{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wihika/INF0619/blob/main/INF0619_Classificacao_de_revisoes_de_filmes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tzsmU3M6CQs"
      },
      "source": [
        "## Trabalho Final — INF-0619 Classificação de Revisões de Filmes  \n",
        "Alunos:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Descrição\n",
        "O site Rotten Tomatoes é uma plataforma amplamente reconhecida que coleta e exibe avaliações de filmes feitas tanto\n",
        "por usuários comuns, referidos como audiência, quanto por críticos especializados em cinema, o que proporciona\n",
        "uma visão abrangente sobre a recepção de um filme. Uma tarefa crítica que surge desse conjunto de dados é a\n",
        "classificação das avaliações, que pode ser realizada de diferentes maneiras, incluindo a análise do sentimento, que\n",
        "identifica opiniões expressas nas críticas como positivas, negativas ou neutras, e a atribuição de notas, que facilita\n",
        "a comparação entre diferentes filmes. Realizar essas análises de forma automática é de grande importância, pois\n",
        "permite processar uma quantidade significativa de dados de maneira eficiente e precisa, ajudando os usuários a\n",
        "fazer escolhas informadas sobre quais filmes assistir e fornecendo insights valiosos sobre tendências de recepção\n",
        "cinematográfica ao longo do tempo.\n",
        "A base de dados deste projeto contém avaliações de usuários, com notas variando entre 0.5 e 5, de 0.5 em 0.5, e\n",
        "avaliações de críticos de cinema, com o sentimento associado (positivo ou negativo).\n",
        "\n",
        "#Objetivo Principal\n",
        "Este projeto envolve dois problemas, sendo uma tarefa binária e uma tarefa multi-classe, cujo objetivo é predizer\n",
        "corretamente o sentimento da avaliação do crítico (classificação binária) e a nota de avaliação do usuário (multiclasse) baseado no texto da avaliação. A métrica que deverá ser utilizada neste projeto é a Acurácia Balanceada.\n",
        "\n",
        "#Técnicas Envolvidas\n",
        "*   Processamento de linguagem natural;\n",
        "*   Processamento e representação de dados textuais;\n",
        "*   Classificação binária;\n",
        "*   Classificação multi-classe.\n",
        "\n",
        "#Desafios\n",
        "*   Para esse projeto, alguns desafios são:\n",
        "*   Explorar técnicas de processamento de linguagem natural;\n",
        "*   Analisar as palavras e termos-chaves de cada classe;\n",
        "*   Lidar com o desbalanceamento de classes;\n",
        "*   Classificar corretamente o sentimento das revisões dos críticos;\n",
        "*   Classificar corretamente a nota da avaliação dos usuários.\n",
        "\n",
        "#Conjunto de Dados\n",
        "*   Kaggle da base de dados (https://www.kaggle.com/datasets/coltonbarger/rotten-tomatoes-reviews-for-online-streaming-shows/data);\n",
        "*   Conjunto de dados (https://drive.google.com/drive/folders/10wfbJmPUqfZNs3HY4_Y_Uw1Ef0hFMRU5).\n"
      ],
      "metadata": {
        "id": "5PYraWzxzYlP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWk3u7rHw3MF"
      },
      "source": [
        "## Instalação das Bibliotecas"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalar as bibliotecas necessárias:"
      ],
      "metadata": {
        "id": "TQM2-64T1HMS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vNcKGybw3MF",
        "outputId": "c84da40c-bbe3-467b-dff5-be30c3df9085"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Collecting bertviz\n",
            "  Downloading bertviz-1.4.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: transformers>=2.0 in /usr/local/lib/python3.10/dist-packages (from bertviz) (4.46.2)\n",
            "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.10/dist-packages (from bertviz) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from bertviz) (4.66.6)\n",
            "Collecting boto3 (from bertviz)\n",
            "  Downloading boto3-1.35.68-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bertviz) (2.32.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from bertviz) (2024.9.11)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from bertviz) (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.0->bertviz) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.0->bertviz) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.0->bertviz) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.0->bertviz) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.0->bertviz) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.0->bertviz) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.0->bertviz) (0.20.3)\n",
            "Collecting botocore<1.36.0,>=1.35.68 (from boto3->bertviz)\n",
            "  Downloading botocore-1.35.68-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->bertviz)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->bertviz)\n",
            "  Downloading s3transfer-0.10.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bertviz) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bertviz) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bertviz) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bertviz) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.68->boto3->bertviz) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0->bertviz) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.68->boto3->bertviz) (1.16.0)\n",
            "Downloading bertviz-1.4.0-py3-none-any.whl (157 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.6/157.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.35.68-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.35.68-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.10.4-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jmespath, botocore, s3transfer, boto3, bertviz\n",
            "Successfully installed bertviz-1.4.0 boto3-1.35.68 botocore-1.35.68 jmespath-1.0.1 s3transfer-0.10.4\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install transformers\n",
        "!pip install bertviz\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chamada das bibliotecas necessárias:"
      ],
      "metadata": {
        "id": "3sEOASEz02Cg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "import numpy\n",
        "import torch\n",
        "import seaborn\n",
        "import matplotlib.pyplot as plot\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_scheduler\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from sklearn.metrics import balanced_accuracy_score, accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from bertviz import model_view, head_view"
      ],
      "metadata": {
        "id": "-W-fnmLX1RXn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMfcgO1L8j8_"
      },
      "source": [
        "## Carregar e preparar os dados"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**critic_reviews**\n",
        "- **Show**: titulo do show avaliado\n",
        "- **Sentiment**: Sentimento sendo 0 negativo e 1 positivo (2 classes)\n",
        "- **Review**: conteúdo da avaliação"
      ],
      "metadata": {
        "id": "BRROKpiS4A-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "critic_df = pandas.read_csv(\"train_critic.csv\", header=0)\n",
        "test_critic_df = pandas.read_csv(\"test_critic.csv\", header=0)"
      ],
      "metadata": {
        "id": "9ujm6YsZ5ZFe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| **Show**                           | **Review**                                                                                       | **Sentiment** |\n",
        "|------------------------------------|--------------------------------------------------------------------------------------------------|---------------|\n",
        "| Bodyguard                          | This has been a brilliant, compulsive, five-star drama...                                        | 1             |\n",
        "| Mad Men                            | With each new season, I try to remind myself that...                                             | 0             |\n",
        "| 1971: The Year That Music Changed Everything | Here's one of the most all-encompassing and stunning...                                         | 1             |\n",
        "| Six Feet Under                     | To me, it was one of the most clever, funny, smart...                                            | 1             |\n",
        "| Pieces of Her                      | Well acted and highly suspenseful, the eight-part drama...                                       | 0             |\n",
        "| ...                                | ...                                                                                              | ...           |\n",
        "| Freaks and Geeks                   | Freaks and Geeks boasts an extremely talented cast...                                            | 1             |\n",
        "| The Gilded Age                     | It's a period piece set in 1882 New York that captures...                                        | 1             |\n",
        "| Joe vs Carole                      | McKinnon and her co-producers must be credited for...                                            | 1             |\n",
        "| Rick and Morty                     | As season openers go, this is a really solid entry...                                            | 1             |\n",
        "| Y: The Last Man                    | Once the show moves past its been-there, watched-that...                                         | 1             |\n"
      ],
      "metadata": {
        "id": "jyiQ9Rci_GWj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**audience_reviews**\n",
        "- **Show**: titulo do show avaliado\n",
        "- **Rating**: nota do show de 0 a 5, com steps de 0.5 (10 classes)\n",
        "- **Review**: conteúdo da avaliação"
      ],
      "metadata": {
        "id": "d-aMdYUn5bs0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eZ5H4gzR4VSU"
      },
      "outputs": [],
      "source": [
        "audience_df = pandas.read_csv(\"train_audience.csv\", header=0)\n",
        "test_audience_df = pandas.read_csv(\"test_audience.csv\", header=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| **Show**                | **Review**                                                                                         | **Rating** |\n",
        "|--------------------------|---------------------------------------------------------------------------------------------------|------------|\n",
        "| Game of Thrones          | Lost all guidance without the book. Somehow ruined the entire legacy...                          | 0.5        |\n",
        "| The Book of Boba Fett    | It felt mostly bizarre. Boba Fett himself seems out of place...                                   | 2.5        |\n",
        "| Safe                     | It started well and got me hooked, but it gets dull by the end...                                 | 3.0        |\n",
        "| Midnight Mass            | Here's what you get in this series: Long-winded speeches, some clever moments...                 | 2.0        |\n",
        "| Star Wars: Visions       | I am a big fan of Star Wars and anime, so I really enjoyed this...                                | 4.5        |\n",
        "| ...                      | ...                                                                                               | ...        |\n",
        "| Ozark                    | Don't watch the last season - anticlimactic. Very disappointing...                                | 1.0        |\n",
        "| Game of Thrones          | I wanted to give this higher for the excellent earlier seasons, but the ending ruins it...        | 1.5        |\n",
        "| Attack on Titan          | This season will make Attack on Titan a masterpiece in storytelling and animation...              | 5.0        |\n",
        "| Watchmen                 | Looks terrible. Story is about some sort of random nonsense...                                    | 0.5        |\n",
        "| Peacemaker               | Fun, exciting, well-written, and enjoyable are the words that come to mind for this series...     | 5.0        |\n"
      ],
      "metadata": {
        "id": "E8kFPxw8_gnE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJqtVALjw3MJ"
      },
      "source": [
        "## Variaveis de configuração\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variaveis gerais"
      ],
      "metadata": {
        "id": "x9ziHsnA8FXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IS_TEST = True  # Variavel para deixar as runs menores para testar o codigo mais rapido\n",
        "MODEL_NAME = \"prajjwal1/bert-tiny\"  # Escolha o modelo conforme sua necessidade\n",
        "NUM_EPOCHS = 35 # Número de épocas\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # Define como rodar dependendo se houver GPU\n",
        "MAX_LEN = 256 # Parametro usado no tokenizer"
      ],
      "metadata": {
        "id": "5s3k3RZw7z0W"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variaveis Critic"
      ],
      "metadata": {
        "id": "jP_xFh9y8Hbq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272,
          "referenced_widgets": [
            "30d6bcadaf5d457bbdc2a2fc9b6fd3f5",
            "4820865a9126472faa8da31d670ff105",
            "a81e10c42c3649ca88bac9c57b998532",
            "95491b505aba47d8968511bf2757eb77",
            "9e408cebbdb6466e8c33aa7d59b61ada",
            "fd1f229d88b64092a667dcd586734b5f",
            "a24828e8578347d5ac1f6063ef6f40d7",
            "adbb9f47d62d4958877524c791aa8b57",
            "03d7d185cf444c19ac6a77845acc2676",
            "db6e2a69c97144c48cb3a20ac1495ff2",
            "3f3a07d6b5db4c3d933593ee03df3d85",
            "b0e113999d2f42b7a0bb91542643389f",
            "e2281c76dedd410faa47697a6907b064",
            "82cecaafa4854a82af4d96c189cbec05",
            "5d3911819bfa4bad96aa96083867ab68",
            "55bb1f13e6774d52864b15ded2f82153",
            "b15c7c63774f45bdbbfe2a60a24a33c3",
            "7eb647d0ac494e568d27244abda8d574",
            "5ccc3a4433c445d99af996eb4614a2c7",
            "c5b74bde0f6045cb8935b18de2459e02",
            "60d697c50e7546e3a054128d1c6ed158",
            "1cc383629dac4ae99a1dec534c922b24",
            "2104928226b640ae88b9611b3912c776",
            "409256a556f641cb9990640426c09c98",
            "8c0b531402184c90be5e62ea8f8145a4",
            "7f201c8750a0413aa6a179736394c3bc",
            "06655be985174439a0886bd95ecd63eb",
            "eb648162ad5c4bfb98069125f02408ed",
            "054a0ee86f5948ed8062862433ff4fdb",
            "9f708e8844b445b9ab0b88d072c80b94",
            "2ddd32bcea2f4fd2970c07878fa91a4c",
            "bca374f044bd4d6d98e7a14d3e3b405f",
            "243aeafb129245938f276995dcd1caf2"
          ]
        },
        "id": "zT9WEDxVw3MJ",
        "outputId": "7e268798-9f4c-48d0-f7eb-2b6fc40f30d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/285 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30d6bcadaf5d457bbdc2a2fc9b6fd3f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0e113999d2f42b7a0bb91542643389f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/17.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2104928226b640ae88b9611b3912c776"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "NUM_LABELS_CRITIC = 2 # Número de classes para a base critic\n",
        "TOKENIZER_CRITIC =  AutoTokenizer.from_pretrained(MODEL_NAME, num_labels=NUM_LABELS_CRITIC)  # Carregar o tokenizer para o critic\n",
        "MODEL_CRITIC = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=NUM_LABELS_CRITIC, output_attentions=False, output_hidden_states=False).to(DEVICE)  # Carregar o modelo de classificação para 2 classes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variaveis Audience"
      ],
      "metadata": {
        "id": "CFjTKNG98KVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_LABELS_AUDIENCE = 10 # Número de classes para a base audience\n",
        "TOKENIZER_AUDIENCE =  AutoTokenizer.from_pretrained(MODEL_NAME, num_labels=NUM_LABELS_AUDIENCE)  # Carregar o tokenizer para o audience\n",
        "MODEL_AUDIENCE = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=NUM_LABELS_AUDIENCE, output_attentions=False, output_hidden_states=False).to(DEVICE)   # Carregar o modelo de classificação para 2 classes"
      ],
      "metadata": {
        "id": "P2L6gkhc7qAV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "678c2eb4-e910-49db-915b-6a36cdb24cf5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73j5C6qlw3MK"
      },
      "source": [
        "### Preparação dos Conjuntos de Dados\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparação dos dados Critic"
      ],
      "metadata": {
        "id": "8n0I2wKx8oGe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pMQarjciw3MK"
      },
      "outputs": [],
      "source": [
        "critic_df = critic_df.replace([numpy.inf, -numpy.inf], numpy.nan)\n",
        "critic_df.dropna(inplace=True)\n",
        "test_critic_df = test_critic_df.replace([numpy.inf, -numpy.inf], numpy.nan)\n",
        "test_critic_df.dropna(inplace=True)\n",
        "distinct_sentiment_labels = critic_df.Sentiment.unique()\n",
        "distinct_sentiment_label_dict = {}\n",
        "for index, label in enumerate(distinct_sentiment_labels):\n",
        "    distinct_sentiment_label_dict[label] = index\n",
        "\n",
        "critic_df['label'] = critic_df.Sentiment.replace(distinct_sentiment_label_dict)\n",
        "critic_df.label = critic_df.label.astype(int)\n",
        "test_critic_df['label'] = test_critic_df.Sentiment.replace(distinct_sentiment_label_dict)\n",
        "test_critic_df.label = test_critic_df.label.astype(int)\n",
        "\n",
        "critic_df['Review'] = critic_df['Review'].astype(str)\n",
        "test_critic_df['Review'] = test_critic_df['Review'].astype(str)\n",
        "\n",
        "# balanceando os dados de treino\n",
        "train_critic_class0 = critic_df[critic_df['label'] == 0]\n",
        "train_critic_class1 = critic_df[critic_df['label'] == 1]\n",
        "sample_size = min(len(train_critic_class0), len(train_critic_class1))\n",
        "train_critic_class0_sample = train_critic_class0.sample(n=sample_size, random_state=42)\n",
        "train_critic_class1_sample = train_critic_class1.sample(n=sample_size, random_state=42)\n",
        "balanced_train_critic_df = pandas.concat([train_critic_class0_sample, train_critic_class1_sample], ignore_index=True)\n",
        "\n",
        "train_critic_data, val_critic_data, train_critic_labels, val_critic_labels = train_test_split(balanced_train_critic_df.index.values,\n",
        "                                                                                              balanced_train_critic_df.label.values,\n",
        "                                                                                              test_size=0.2, random_state=42,\n",
        "                                                                                              stratify=balanced_train_critic_df.label.values)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "critic_df.label.value_counts()"
      ],
      "metadata": {
        "id": "xXRgWPK124dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "32112d68-c9c7-49de-cadc-f00440a6e7bf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "0    9995\n",
              "1    1836\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1836</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " pandas.Series(train_critic_labels).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "yBpatW8gq-1v",
        "outputId": "87f50626-7727-47ac-9721-bff097eeaef8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    1469\n",
              "0    1468\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1468</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_critic_data_train = TOKENIZER_CRITIC.batch_encode_plus(\n",
        "    balanced_train_critic_df.loc[train_critic_data].Review.values.tolist(),\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length = MAX_LEN,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "encoded_critic_data_val = TOKENIZER_CRITIC.batch_encode_plus(\n",
        "    balanced_train_critic_df.loc[val_critic_data].Review.values.tolist(),\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length = MAX_LEN,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "encoded_critic_data_test = TOKENIZER_CRITIC.batch_encode_plus(\n",
        "    test_critic_df.Review.values.tolist(),\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length = MAX_LEN,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "input_ids_train_critic = encoded_critic_data_train['input_ids']\n",
        "input_ids_val_critic = encoded_critic_data_val['input_ids']\n",
        "input_ids_test_critic = encoded_critic_data_test['input_ids']\n",
        "\n",
        "attention_mask_train_critic = encoded_critic_data_train['attention_mask']\n",
        "attention_mask_val_critic = encoded_critic_data_val['attention_mask']\n",
        "attention_mask_test_critic = encoded_critic_data_test['attention_mask']\n",
        "\n",
        "labels_train_critic = torch.tensor(balanced_train_critic_df.loc[train_critic_data].label.values)\n",
        "labels_val_critic =  torch.tensor(balanced_train_critic_df.loc[val_critic_data].label.values)\n",
        "labels_test_critic = torch.tensor(test_critic_df.label.values)\n",
        "\n",
        "dataset_train_critic = TensorDataset(input_ids_train_critic, attention_mask_train_critic, labels_train_critic)\n",
        "dataset_val_critic = TensorDataset(input_ids_val_critic, attention_mask_val_critic, labels_val_critic)\n",
        "dataset_test_critic = TensorDataset(input_ids_test_critic, attention_mask_test_critic, labels_test_critic)\n",
        "\n",
        "dataloader_train_critic = DataLoader(dataset_train_critic)\n",
        "dataloader_val_critic = DataLoader(dataset_val_critic)\n",
        "dataloader_test_critic = DataLoader(dataset_test_critic)"
      ],
      "metadata": {
        "id": "jejtSjiM-jY1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9faac607-6b4c-4a1d-a6e2-0392963e549c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2834: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2834: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparação dos dados Audience"
      ],
      "metadata": {
        "id": "ygXHGAP99zn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audience_df = audience_df.replace([numpy.inf, -numpy.inf], numpy.nan)\n",
        "audience_df.dropna(inplace=True)\n",
        "test_audience_df = test_audience_df.replace([numpy.inf, -numpy.inf], numpy.nan)\n",
        "test_audience_df.dropna(inplace=True)\n",
        "distinct_rating_labels = audience_df.Rating.unique()\n",
        "distinct_rating_label_dict = {}\n",
        "for index, label in enumerate(distinct_rating_labels):\n",
        "    distinct_rating_label_dict[label] = index\n",
        "\n",
        "audience_df['label'] = audience_df.Rating.replace(distinct_rating_label_dict)\n",
        "audience_df.label = audience_df.label.astype(int)\n",
        "test_audience_df['label'] = test_audience_df.Rating.replace(distinct_rating_label_dict)\n",
        "test_audience_df.label = test_audience_df.label.astype(int)\n",
        "\n",
        "audience_df['Review'] = audience_df['Review'].astype(str)\n",
        "test_audience_df['Review'] = test_audience_df['Review'].astype(str)\n",
        "\n",
        "# balanceando os dados de treino\n",
        "train_audience_class0 = audience_df[audience_df['label'] == 0]\n",
        "train_audience_class1 = audience_df[audience_df['label'] == 1]\n",
        "train_audience_class2 = audience_df[audience_df['label'] == 2]\n",
        "train_audience_class3 = audience_df[audience_df['label'] == 3]\n",
        "train_audience_class4 = audience_df[audience_df['label'] == 4]\n",
        "train_audience_class5 = audience_df[audience_df['label'] == 5]\n",
        "train_audience_class6 = audience_df[audience_df['label'] == 6]\n",
        "train_audience_class7 = audience_df[audience_df['label'] == 7]\n",
        "train_audience_class8 = audience_df[audience_df['label'] == 8]\n",
        "train_audience_class9 = audience_df[audience_df['label'] == 9]\n",
        "sample_size = min(len(train_audience_class0), len(train_audience_class1), len(train_audience_class2), len(train_audience_class3), len(train_audience_class4), len(train_audience_class5), len(train_audience_class6), len(train_audience_class7), len(train_audience_class8), len(train_audience_class9))\n",
        "train_audience_class0_sample = train_audience_class0.sample(n=sample_size, random_state=42)\n",
        "train_audience_class1_sample = train_audience_class1.sample(n=sample_size, random_state=42)\n",
        "train_audience_class2_sample = train_audience_class2.sample(n=sample_size, random_state=42)\n",
        "train_audience_class3_sample = train_audience_class3.sample(n=sample_size, random_state=42)\n",
        "train_audience_class4_sample = train_audience_class4.sample(n=sample_size, random_state=42)\n",
        "train_audience_class5_sample = train_audience_class5.sample(n=sample_size, random_state=42)\n",
        "train_audience_class6_sample = train_audience_class6.sample(n=sample_size, random_state=42)\n",
        "train_audience_class7_sample = train_audience_class7.sample(n=sample_size, random_state=42)\n",
        "train_audience_class8_sample = train_audience_class8.sample(n=sample_size, random_state=42)\n",
        "train_audience_class9_sample = train_audience_class9.sample(n=sample_size, random_state=42)\n",
        "balanced_train_audience_df = pandas.concat([train_audience_class0_sample, train_audience_class1_sample, train_audience_class2_sample, train_audience_class3_sample, train_audience_class4_sample, train_audience_class5_sample, train_audience_class6_sample, train_audience_class7_sample, train_audience_class8_sample, train_audience_class9_sample], ignore_index=True)\n",
        "\n",
        "train_audience_data, val_audience_data, train_audience_labels, val_audience_labels = train_test_split(balanced_train_audience_df.index.values,\n",
        "                                                                                                      balanced_train_audience_df.label.values,\n",
        "                                                                                                      test_size=0.2, random_state=42,\n",
        "                                                                                                      stratify=balanced_train_audience_df.label.values)"
      ],
      "metadata": {
        "id": "OAJx7Zyy95eS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audience_df.label.value_counts()"
      ],
      "metadata": {
        "id": "p_xB-bD53A0x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "outputId": "3114b42f-032e-4f33-ab3f-23866780cdf3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "5    23642\n",
              "0     7016\n",
              "8     3869\n",
              "4     3792\n",
              "7     3309\n",
              "3     2690\n",
              "6     2340\n",
              "2     2141\n",
              "9     2040\n",
              "1     1577\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>23642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1577</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " pandas.Series(train_audience_labels).value_counts()"
      ],
      "metadata": {
        "id": "kwv01TxsQpTg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "8c2a6b87-4c40-4767-b4d0-07cb4a78aca3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8    1262\n",
              "2    1262\n",
              "1    1262\n",
              "5    1262\n",
              "0    1262\n",
              "7    1262\n",
              "9    1261\n",
              "3    1261\n",
              "4    1261\n",
              "6    1261\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1261</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_audience_data_train = TOKENIZER_AUDIENCE.batch_encode_plus(\n",
        "    balanced_train_audience_df.loc[train_audience_data].Review.values.tolist(),\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length = MAX_LEN,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "encoded_audience_data_val = TOKENIZER_AUDIENCE.batch_encode_plus(\n",
        "    balanced_train_audience_df.loc[val_audience_data].Review.values.tolist(),\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length = MAX_LEN,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "encoded_audience_data_test = TOKENIZER_AUDIENCE.batch_encode_plus(\n",
        "    test_audience_df.Review.values.tolist(),\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length = MAX_LEN,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "input_ids_train_audience = encoded_audience_data_train['input_ids']\n",
        "input_ids_val_audience = encoded_audience_data_val['input_ids']\n",
        "input_ids_test_audience = encoded_audience_data_test['input_ids']\n",
        "\n",
        "attention_mask_train_audience = encoded_audience_data_train['attention_mask']\n",
        "attention_mask_val_audience = encoded_audience_data_val['attention_mask']\n",
        "attention_mask_test_audience = encoded_audience_data_test['attention_mask']\n",
        "\n",
        "labels_train_audience = torch.tensor(balanced_train_audience_df.loc[train_audience_data].label.values)\n",
        "labels_val_audience =  torch.tensor(balanced_train_audience_df.loc[val_audience_data].label.values)\n",
        "labels_test_audience = torch.tensor(test_audience_df.label.values)\n",
        "\n",
        "dataset_train_audience = TensorDataset(input_ids_train_audience, attention_mask_train_audience, labels_train_audience)\n",
        "dataset_val_audience = TensorDataset(input_ids_val_audience, attention_mask_val_audience, labels_val_audience)\n",
        "dataset_test_audience = TensorDataset(input_ids_test_audience, attention_mask_test_audience, labels_test_audience)\n",
        "\n",
        "dataloader_train_audience = DataLoader(dataset_train_audience)\n",
        "dataloader_val_audience = DataLoader(dataset_val_audience)\n",
        "dataloader_test_audience = DataLoader(dataset_test_audience)"
      ],
      "metadata": {
        "id": "CYOKKCw0CALZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d4cf16a-01c5-452b-e9be-b5901262fd35"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2834: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2834: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhgoibF2w3ML"
      },
      "source": [
        "### Funções auxiliares\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Função Test** para testar o modelo, parametros são modelo e o dataloader (inputs, attention masks e labels) usados na avaliação. Retorna o loss, o array com a probabilidade de cada classe possível e os labels verdade usados."
      ],
      "metadata": {
        "id": "aAcKPEK9DMJp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "tags": [],
        "id": "bBMvVPzjybxT"
      },
      "outputs": [],
      "source": [
        "def Test(model, dataloader, device):\n",
        "    model.eval()\n",
        "\n",
        "    loss_total = 0\n",
        "    pred, label = [], []\n",
        "\n",
        "    for batch in dataloader:\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        inputs = {\n",
        "                    'input_ids': batch[0].to(device),\n",
        "                    'attention_mask': batch[1].to(device),\n",
        "                    'labels': batch[2].to(device)\n",
        "                  }\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_total = loss_total + loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        pred.append(logits)\n",
        "        label.append(label_ids)\n",
        "\n",
        "    average_loss = loss_total/len(dataloader)\n",
        "    pred = numpy.concatenate(pred, axis=0)\n",
        "    label = numpy.concatenate(label, axis=0)\n",
        "    return average_loss, pred, label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Função Treino** para treinar o modelo, parametros são modelo, nome do modelo, o dataloader de treino (inputs, attention masks e labels), o dataloader de validação, o otimizador, um scheduler (outro tipo de otimizador), numero de épocas e o device (cpu ou gpu) usados no treino. Retorna o modelo treinado."
      ],
      "metadata": {
        "id": "RW6jHXKCj5es"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Train(model, model_name, dataloader_train, dataloader_val, optimizer, scheduler, num_epochs, device):\n",
        "  train_loss_list = []\n",
        "  val_loss_list = []\n",
        "  train_accuracy_list = []\n",
        "  val_accuracy_list = []\n",
        "  train_balanced_accuracy_list = []\n",
        "  val_balanced_accuracy_list = []\n",
        "\n",
        "  for epoch in range(1, num_epochs + 1):\n",
        "      model.train()\n",
        "\n",
        "      loss_total = 0\n",
        "      all_preds = []\n",
        "      all_labels = []\n",
        "\n",
        "      for batch in dataloader_train:\n",
        "          model.zero_grad()\n",
        "\n",
        "          batch = tuple(b.to(device) for b in batch)\n",
        "\n",
        "          inputs = {\n",
        "                      'input_ids': batch[0].to(device),\n",
        "                      'attention_mask': batch[1].to(device),\n",
        "                      'labels': batch[2].to(device)\n",
        "                    }\n",
        "          outputs = model(**inputs)\n",
        "\n",
        "          loss = outputs[0]\n",
        "          loss_total = loss_total + loss.item()\n",
        "          loss.backward()\n",
        "\n",
        "          torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0).to(device)\n",
        "\n",
        "          optimizer.step()\n",
        "          scheduler.step()\n",
        "\n",
        "          _, preds = torch.max(outputs[1], 1)  # Get predicted class labels\n",
        "          all_preds.extend(preds.cpu().numpy())\n",
        "          all_labels.extend(batch[2].cpu().numpy())\n",
        "\n",
        "      torch.save(model.state_dict(), f'finetuned_{model_name}_{epoch}.model')\n",
        "      print(f'Epoca {epoch}')\n",
        "\n",
        "      loss_avg_train = loss_total/len(dataloader_train)\n",
        "      train_loss_list.append(loss_avg_train)\n",
        "      print(f'Traning Loss: {loss_avg_train}')\n",
        "      val_loss, preds, labels = Test(model, dataloader_val, device)\n",
        "      val_loss_list.append(val_loss)\n",
        "      print(f'Validation Loss: {val_loss}')\n",
        "\n",
        "      train_accuracy = accuracy_score(all_labels, all_preds)\n",
        "      train_accuracy_list.append(train_accuracy)\n",
        "      print(f'Train Accuracy: {train_accuracy}')\n",
        "      preds_array = numpy.argmax(preds, axis=1)\n",
        "      val_accuracy = accuracy_score(labels, preds_array)\n",
        "      val_accuracy_list.append(val_accuracy)\n",
        "      print(f'Validation Accuracy: {val_accuracy}')\n",
        "\n",
        "      train_balanced_accuracy = balanced_accuracy_score(all_labels, all_preds)\n",
        "      train_balanced_accuracy_list.append(train_balanced_accuracy)\n",
        "      print(f'Train Balanced Accuracy: {train_balanced_accuracy}')\n",
        "      val_balanced_accuracy = balanced_accuracy_score(labels, preds_array)\n",
        "      val_balanced_accuracy_list.append(val_balanced_accuracy)\n",
        "      print(f'Validation Balanced Accuracy: {val_balanced_accuracy}')\n",
        "\n",
        "  data = {'train_loss': train_loss_list, 'val_loss': val_loss_list, 'train_accuracy': train_accuracy_list, 'val_accuracy': val_accuracy_list, 'train_balanced_accuracy': train_balanced_accuracy_list, 'val_balanced_accuracy': val_balanced_accuracy_list}\n",
        "  df = pandas.DataFrame(data)\n",
        "\n",
        "  return model, df"
      ],
      "metadata": {
        "id": "8WyjA1dLH6GA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Função de Plot da Matriz de Confusão** para analisar o modelo, parametros labels verdade, classes preditas, titulo e lista de possiveis classes. Plota a matriz."
      ],
      "metadata": {
        "id": "W0M7NgHJkicV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ConfusionMatrix(labels, preds_array, title, classes_list):\n",
        "  cm = confusion_matrix(labels, preds_array)\n",
        "  cm_normalized = cm.astype('float') / len(labels)\n",
        "\n",
        "  plot.figure(figsize=(8, 6))\n",
        "  seaborn.heatmap(cm_normalized, annot=True, fmt=\".0%\", cmap=\"Blues\",\n",
        "              xticklabels=classes_list, yticklabels=classes_list)\n",
        "  plot.xlabel(\"Predicted Labels\")\n",
        "  plot.ylabel(\"True Labels\")\n",
        "  plot.title(title)\n",
        "  plot.show()"
      ],
      "metadata": {
        "id": "ZJnycd-Id12x"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LC01Yf6iw3MM"
      },
      "source": [
        "### Treino Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo Critic"
      ],
      "metadata": {
        "id": "f4Hd5oQOII-b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "tags": [],
        "id": "VfBev8v-ybxU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5ce5f0b2-afa1-431f-e29a-8fbb50b9e72e"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoca 1\n",
            "Traning Loss: 0.6937125490196392\n",
            "Validation Loss: 0.6921520617543434\n",
            "Train Accuracy: 0.49846782431052095\n",
            "Validation Accuracy: 0.5156462585034014\n",
            "Train Balanced Accuracy: 0.4984015706990798\n",
            "Validation Balanced Accuracy: 0.5161969849543893\n",
            "Epoca 2\n",
            "Traning Loss: 0.6886044123422786\n",
            "Validation Loss: 0.6884332857164396\n",
            "Train Accuracy: 0.5379639087504257\n",
            "Validation Accuracy: 0.5482993197278911\n",
            "Train Balanced Accuracy: 0.5379268738302763\n",
            "Validation Balanced Accuracy: 0.5488427022864589\n",
            "Epoca 3\n",
            "Traning Loss: 0.6766883389841021\n",
            "Validation Loss: 0.6718315871799884\n",
            "Train Accuracy: 0.5846101464078992\n",
            "Validation Accuracy: 0.5727891156462585\n",
            "Train Balanced Accuracy: 0.5846342114879164\n",
            "Validation Balanced Accuracy: 0.5731067112901316\n",
            "Epoca 4\n",
            "Traning Loss: 0.6803777768959348\n",
            "Validation Loss: 0.9769041686033716\n",
            "Train Accuracy: 0.6258086482805584\n",
            "Validation Accuracy: 0.5863945578231292\n",
            "Train Balanced Accuracy: 0.6257973597861712\n",
            "Validation Balanced Accuracy: 0.5868713718753702\n",
            "Epoca 5\n",
            "Traning Loss: 0.956729557323956\n",
            "Validation Loss: 1.4205615670996763\n",
            "Train Accuracy: 0.6704119850187266\n",
            "Validation Accuracy: 0.6217687074829932\n",
            "Train Balanced Accuracy: 0.6703913114446982\n",
            "Validation Balanced Accuracy: 0.6221049046321525\n",
            "Epoca 6\n",
            "Traning Loss: 1.0281573496403786\n",
            "Validation Loss: 1.47930085783837\n",
            "Train Accuracy: 0.7126319373510385\n",
            "Validation Accuracy: 0.6394557823129252\n",
            "Train Balanced Accuracy: 0.7126163695483221\n",
            "Validation Balanced Accuracy: 0.6397309264305178\n",
            "Epoca 7\n",
            "Traning Loss: 1.0000646843542913\n",
            "Validation Loss: 1.4173912569310287\n",
            "Train Accuracy: 0.7449778685733742\n",
            "Validation Accuracy: 0.6761904761904762\n",
            "Train Balanced Accuracy: 0.7449663620361215\n",
            "Validation Balanced Accuracy: 0.6763601765193696\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-2c5f5e7be3b4>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mMODEL_CRITIC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_critic_train_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_CRITIC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CRITIC'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_train_critic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_val_critic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_critic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler_critic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-bcf454ce2147>\u001b[0m in \u001b[0;36mTrain\u001b[0;34m(model, model_name, dataloader_train, dataloader_val, optimizer, scheduler, num_epochs, device)\u001b[0m\n\u001b[1;32m     32\u001b[0m           \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m           \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opt_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[union-attr]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped_by_lr_sched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                             )\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    218\u001b[0m             )\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             adamw(\n\u001b[0m\u001b[1;32m    221\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mmaybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdisabled_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adamw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    783\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "optimizer_critic = AdamW(MODEL_CRITIC.parameters(),\n",
        "                  lr=1e-5)\n",
        "\n",
        "num_training_steps = len(dataloader_train_critic) * NUM_EPOCHS\n",
        "\n",
        "num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "scheduler_critic = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer_critic,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    num_training_steps=num_training_steps\n",
        ")\n",
        "\n",
        "MODEL_CRITIC, model_critic_train_results = Train(MODEL_CRITIC, 'CRITIC', dataloader_train_critic, dataloader_val_critic, optimizer_critic, scheduler_critic, NUM_EPOCHS, DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "0heaXvpWgyaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_critic_train_results.plot(kind='line')\n",
        "plot.title('Loss e Acuracia Critic pós Treino')\n",
        "plot.xticks(range(0, len(model_critic_train_results), 1))\n",
        "plot.xlabel('Época')\n",
        "plot.ylabel('Valores')\n",
        "plot.legend(loc='best')\n",
        "plot.show()"
      ],
      "metadata": {
        "id": "5taylaC0tSRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo Audience"
      ],
      "metadata": {
        "id": "eAzZvkjFIPbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_audience = AdamW(MODEL_AUDIENCE.parameters(),\n",
        "                  lr=1e-5)\n",
        "\n",
        "num_training_steps = len(dataloader_train_audience) * NUM_EPOCHS\n",
        "\n",
        "num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "scheduler_audience = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer_audience,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    num_training_steps=num_training_steps\n",
        ")\n",
        "\n",
        "MODEL_AUDIENCE, model_audience_train_results = Train(MODEL_AUDIENCE, 'AUDIENCE', dataloader_train_audience, dataloader_val_audience, optimizer_audience, scheduler_audience, NUM_EPOCHS, DEVICE)"
      ],
      "metadata": {
        "id": "Nl5GE-HmIM1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Epoca | Training Loss | Validation Loss | Train Accuracy | Validation Accuracy | Train Balanced Accuracy | Validation Balanced Accuracy |\n",
        "|-------|---------------|-----------------|----------------|----------------------|--------------------------|-----------------------------|\n",
        "| 1     | 2.3076        | 2.2952          | 0.1100         | 0.1170              | 0.1100                  | 0.1171                      |\n",
        "| 2     | 2.2756        | 2.2313          | 0.1344         | 0.1636              | 0.1343                  | 0.1637                      |\n",
        "| 3     | 2.1227        | 2.0159          | 0.1994         | 0.2257              | 0.1994                  | 0.2258                      |\n",
        "| 4     | 1.9660        | 1.9382          | 0.2428         | 0.2438              | 0.2428                  | 0.2439                      |\n",
        "| 5     | 1.8965        | 1.9425          | 0.2689         | 0.2657              | 0.2689                  | 0.2658                      |\n",
        "| 6     | 1.8691        | 1.9683          | 0.2845         | 0.2555              | 0.2845                  | 0.2556                      |\n",
        "| 7     | 1.8491        | 1.9938          | 0.3074         | 0.2670              | 0.3074                  | 0.2671                      |\n",
        "| 8     | 1.8224        | 2.0254          | 0.3198         | 0.2768              | 0.3198                  | 0.2769                      |\n",
        "| 9     | 1.7977        | 2.0491          | 0.3387         | 0.2730              | 0.3387                  | 0.2731                      |\n",
        "| 10    | 1.7690        | 2.0960          | 0.3585         | 0.2663              | 0.3585                  | 0.2664                      |\n",
        "| 11    | 1.7298        | 2.1217          | 0.3756         | 0.2651              | 0.3755                  | 0.2651                      |\n",
        "| 12    | 1.7112        | 2.1443          | 0.3897         | 0.2777              | 0.3897                  | 0.2778                      |\n",
        "| 13    | 1.7004        | 2.1766          | 0.3976         | 0.2730              | 0.3976                  | 0.2731                      |\n",
        "| 14    | 1.6594        | 2.2213          | 0.4181         | 0.2768              | 0.4181                  | 0.2769                      |\n",
        "| 15    | 1.6485        | 2.2794          | 0.4216         | 0.2765              | 0.4216                  | 0.2765                      |\n",
        "| 16    | 1.6385        | 2.3401          | 0.4402         | 0.2708              | 0.4401                  | 0.2708                      |\n",
        "| 17    | 1.6083        | 2.3982          | 0.4459         | 0.2717              | 0.4458                  | 0.2718                      |\n",
        "| 18    | 1.5867        | 2.3740          | 0.4595         | 0.2708              | 0.4595                  | 0.2708                      |\n",
        "| 19    | 1.5657        | 2.4128          | 0.4654         | 0.2628              | 0.4654                  | 0.2629                      |\n",
        "| 20    | 1.5528        | 2.4242          | 0.4776         | 0.2632              | 0.4776                  | 0.2632                      |\n",
        "| 21    | 1.5531        | 2.4692          | 0.4757         | 0.2682              | 0.4757                  | 0.2683                      |\n",
        "| 22    | 1.5250        | 2.4689          | 0.4894         | 0.2676              | 0.4894                  | 0.2676                      |\n",
        "| 23    | 1.5018        | 2.5186          | 0.4937         | 0.2746              | 0.4937                  | 0.2746                      |\n",
        "| 24    | 1.4831        | 2.5333          | 0.5093         | 0.2689              | 0.5093                  | 0.2689                      |\n",
        "| 25    | 1.4878        | 2.5414          | 0.5034         | 0.2651              | 0.5034                  | 0.2651                      |\n",
        "| 26    | 1.4657        | 2.5630          | 0.5167         | 0.2651              | 0.5167                  | 0.2651                      |\n",
        "| 27    | 1.4639        | 2.5902          | 0.5160         | 0.2692              | 0.5160                  | 0.2692                      |\n",
        "| 28    | 1.4489        | 2.6192          | 0.5295         | 0.2692              | 0.5295                  | 0.2692                      |\n",
        "| 29    | 1.4481        | 2.6046          | 0.5287         | 0.2711              | 0.5287                  | 0.2711                      |\n",
        "| 30    | 1.4522        | 2.6461          | 0.5249         | 0.2733              | 0.5249                  | 0.2733                      |\n",
        "| 31    | 1.4476        | 2.6654          | 0.5251         | 0.2692              | 0.5251                  | 0.2692                      |\n",
        "| 32    | 1.4314        | 2.6581          | 0.5363         | 0.2685              | 0.5363                  | 0.2686                      |\n",
        "| 33    | 1.4363        | 2.6855          | 0.5287         | 0.2730              | 0.5287                  | 0.2730                      |\n",
        "| 34    | 1.4286        | 2.6901          | 0.5362         | 0.2724              | 0.5362                  | 0.2724                      |\n",
        "| 35    | 1.4139        | 2.6866          | 0.5409         | 0.2695              | 0.5409                  | 0.2695                      |\n"
      ],
      "metadata": {
        "id": "3hZPIBAjsYvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_audience_train_results.plot(kind='line')\n",
        "plot.title('Loss e Acuracia Audience pós Treino')\n",
        "plot.xticks(range(0, len(model_audience_train_results), 1))\n",
        "plot.xlabel('Época')\n",
        "plot.ylabel('Valores')\n",
        "plot.legend(loc='best')\n",
        "plot.show()"
      ],
      "metadata": {
        "id": "FLcKPAVfvR-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmhWYVuxw3MM"
      },
      "source": [
        "### Avaliação do Modelo no Conjunto Test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo Critic"
      ],
      "metadata": {
        "id": "0jA-Gt3oI7Hh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "WcG2_Tk9ybxV"
      },
      "outputs": [],
      "source": [
        "best_epoch_critic = 1\n",
        "model_config_critic = f'finetuned_CRITIC_{best_epoch_critic}.model'\n",
        "best_model_critic = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=NUM_LABELS_CRITIC, output_attentions=True, output_hidden_states=False)\n",
        "best_model_critic.load_state_dict(torch.load(model_config_critic, map_location=torch.device('cpu')))\n",
        "best_model_critic.to(DEVICE)\n",
        "\n",
        "print(\"Melhor modelo\")\n",
        "_, preds, labels = Test(best_model_critic, dataloader_test_critic, DEVICE)\n",
        "print(f'Test Loss: {_}')\n",
        "preds_array = numpy.argmax(preds, axis=1)\n",
        "val_accuracy_2 = accuracy_score(labels, preds_array)\n",
        "print(f'Test Accuracy: {val_accuracy_2}')\n",
        "val_balanced_accuracy_2 = balanced_accuracy_score(labels, preds_array)\n",
        "print(f'Test Balanced Accuracy: {val_balanced_accuracy_2}')\n",
        "\n",
        "ConfusionMatrix(labels, preds_array, title=\"Matrix de confusão - Modelo Critic\", classes_list=distinct_sentiment_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo Audience"
      ],
      "metadata": {
        "id": "z92QdFJbJrT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_epoch_audience = 1\n",
        "model_config_audience = f'finetuned_AUDIENCE_{best_epoch_audience}.model'\n",
        "best_model_audience = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=NUM_LABELS_AUDIENCE, output_attentions=True, output_hidden_states=False)\n",
        "best_model_audience.load_state_dict(torch.load(model_config_audience, map_location=torch.device('cpu')))\n",
        "best_model_audience.to(DEVICE)\n",
        "\n",
        "print(\"Melhor modelo\")\n",
        "_, preds, labels = Test(best_model_audience, dataloader_test_audience, DEVICE)\n",
        "print(f'Test Loss: {_}')\n",
        "preds_array = numpy.argmax(preds, axis=1)\n",
        "val_accuracy_2 = accuracy_score(labels, preds_array)\n",
        "print(f'Test Accuracy: {val_accuracy_2}')\n",
        "val_balanced_accuracy_2 = balanced_accuracy_score(labels, preds_array)\n",
        "print(f'Test Balanced Accuracy: {val_balanced_accuracy_2}')\n",
        "\n",
        "ConfusionMatrix(labels, preds_array, title=\"Matrix de confusão - Modelo Audience\", classes_list=distinct_rating_labels)"
      ],
      "metadata": {
        "id": "n6vFHrfMJr6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9GwIIfPw3MN"
      },
      "source": [
        "### Análise do Mecanismo de Atenção com BertViz\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo Critic"
      ],
      "metadata": {
        "id": "riSq6GAkLO5J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "MP2-rOdFybxW"
      },
      "outputs": [],
      "source": [
        "input_ids=[]\n",
        "for batch in dataloader_test_critic:\n",
        "    input_ids.append(batch[0])\n",
        "\n",
        "print(f'Modelo Critic')\n",
        "correct_cases_critic = [(text, true, pred) for text, true, pred in zip(input_ids, labels_test_critic, preds_array) if true == pred]\n",
        "print(f'Número de acertos: {len(correct_cases_critic)}')\n",
        "\n",
        "decoded_correct_text_critic = TOKENIZER_CRITIC.decode(torch.tensor(correct_cases_critic[0][0][0].tolist()), skip_special_tokens=True)\n",
        "print(f'Texto caso correto: {decoded_correct_text_critic}')\n",
        "\n",
        "incorrect_cases_critic =[(text, true, pred) for text, true, pred in zip(input_ids, labels_test_critic, preds_array) if true != pred]\n",
        "print(f'Número de incorretos: {len(incorrect_cases_critic)}')\n",
        "\n",
        "decoded_incorrect_text_critic = TOKENIZER_CRITIC.decode(torch.tensor(incorrect_cases_critic[0][0][0].tolist()), skip_special_tokens=True)\n",
        "print(f'Texto caso incorreto: {decoded_incorrect_text_critic}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "JskSaLU7ybxW"
      },
      "outputs": [],
      "source": [
        "model = best_model_critic\n",
        "print(\"Análise para um comentário que foi corretamente predito\")\n",
        "inputs = TOKENIZER_CRITIC.encode(decoded_correct_text_critic, return_tensors='pt').to(DEVICE)\n",
        "outputs = model(inputs)\n",
        "attention = outputs[-1]\n",
        "tokens = TOKENIZER_CRITIC.convert_ids_to_tokens(inputs[0])\n",
        "head_view(attention, tokens)\n",
        "model_view(attention, tokens)\n",
        "\n",
        "print(\"Análise para um comentário que foi incorretamente predito\")\n",
        "inputs = TOKENIZER_CRITIC.encode(decoded_incorrect_text_critic, return_tensors='pt').to(DEVICE)\n",
        "outputs = model(inputs)\n",
        "attention = outputs[-1]\n",
        "tokens = TOKENIZER_CRITIC.convert_ids_to_tokens(inputs[0])\n",
        "head_view(attention, tokens)\n",
        "model_view(attention, tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo Audience"
      ],
      "metadata": {
        "id": "u0EI0NaiK9iv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids=[]\n",
        "for batch in dataloader_test_audience:\n",
        "    input_ids.append(batch[0])\n",
        "\n",
        "print(f'Modelo Audience')\n",
        "correct_cases_audience = [(text, true, pred) for text, true, pred in zip(input_ids, labels_test_audience, preds_array) if true == pred]\n",
        "print(f'Número de acertos: {len(correct_cases_audience)}')\n",
        "\n",
        "decoded_correct_text_audience = TOKENIZER_AUDIENCE.decode(torch.tensor(correct_cases_audience[0][0][0].tolist()), skip_special_tokens=True)\n",
        "print(f'Texto caso correto: {decoded_correct_text_audience}')\n",
        "\n",
        "incorrect_cases_audience =[(text, true, pred) for text, true, pred in zip(input_ids, labels_test_audience, preds_array) if true != pred]\n",
        "print(f'Número de incorretos: {len(incorrect_cases_audience)}')\n",
        "\n",
        "decoded_incorrect_text_audience = TOKENIZER_AUDIENCE.decode(torch.tensor(incorrect_cases_audience[0][0][0].tolist()), skip_special_tokens=True)\n",
        "print(f'Texto caso incorreto: {decoded_incorrect_text_audience}')"
      ],
      "metadata": {
        "id": "GEqPvWQBK864"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = best_model_audience\n",
        "print(\"Análise para um comentário que foi corretamente predito\")\n",
        "inputs = TOKENIZER_AUDIENCE.encode(decoded_correct_text_audience, return_tensors='pt').to(DEVICE)\n",
        "outputs = model(inputs)\n",
        "attention = outputs[-1]\n",
        "tokens = TOKENIZER_AUDIENCE.convert_ids_to_tokens(inputs[0])\n",
        "head_view(attention, tokens)\n",
        "model_view(attention, tokens)\n",
        "\n",
        "print(\"Análise para um comentário que foi incorretamente predito\")\n",
        "inputs = TOKENIZER_AUDIENCE.encode(decoded_incorrect_text_audience, return_tensors='pt').to(DEVICE)\n",
        "outputs = model(inputs)\n",
        "attention = outputs[-1]\n",
        "tokens = TOKENIZER_AUDIENCE.convert_ids_to_tokens(inputs[0])\n",
        "head_view(attention, tokens)\n",
        "model_view(attention, tokens)"
      ],
      "metadata": {
        "id": "Mq7Lkn4RMgCv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "conda_pytorch_p310",
      "language": "python",
      "name": "conda_pytorch_p310"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "30d6bcadaf5d457bbdc2a2fc9b6fd3f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4820865a9126472faa8da31d670ff105",
              "IPY_MODEL_a81e10c42c3649ca88bac9c57b998532",
              "IPY_MODEL_95491b505aba47d8968511bf2757eb77"
            ],
            "layout": "IPY_MODEL_9e408cebbdb6466e8c33aa7d59b61ada"
          }
        },
        "4820865a9126472faa8da31d670ff105": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd1f229d88b64092a667dcd586734b5f",
            "placeholder": "​",
            "style": "IPY_MODEL_a24828e8578347d5ac1f6063ef6f40d7",
            "value": "config.json: 100%"
          }
        },
        "a81e10c42c3649ca88bac9c57b998532": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adbb9f47d62d4958877524c791aa8b57",
            "max": 285,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_03d7d185cf444c19ac6a77845acc2676",
            "value": 285
          }
        },
        "95491b505aba47d8968511bf2757eb77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db6e2a69c97144c48cb3a20ac1495ff2",
            "placeholder": "​",
            "style": "IPY_MODEL_3f3a07d6b5db4c3d933593ee03df3d85",
            "value": " 285/285 [00:00&lt;00:00, 3.48kB/s]"
          }
        },
        "9e408cebbdb6466e8c33aa7d59b61ada": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd1f229d88b64092a667dcd586734b5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a24828e8578347d5ac1f6063ef6f40d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "adbb9f47d62d4958877524c791aa8b57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03d7d185cf444c19ac6a77845acc2676": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db6e2a69c97144c48cb3a20ac1495ff2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f3a07d6b5db4c3d933593ee03df3d85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0e113999d2f42b7a0bb91542643389f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2281c76dedd410faa47697a6907b064",
              "IPY_MODEL_82cecaafa4854a82af4d96c189cbec05",
              "IPY_MODEL_5d3911819bfa4bad96aa96083867ab68"
            ],
            "layout": "IPY_MODEL_55bb1f13e6774d52864b15ded2f82153"
          }
        },
        "e2281c76dedd410faa47697a6907b064": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b15c7c63774f45bdbbfe2a60a24a33c3",
            "placeholder": "​",
            "style": "IPY_MODEL_7eb647d0ac494e568d27244abda8d574",
            "value": "vocab.txt: 100%"
          }
        },
        "82cecaafa4854a82af4d96c189cbec05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ccc3a4433c445d99af996eb4614a2c7",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c5b74bde0f6045cb8935b18de2459e02",
            "value": 231508
          }
        },
        "5d3911819bfa4bad96aa96083867ab68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60d697c50e7546e3a054128d1c6ed158",
            "placeholder": "​",
            "style": "IPY_MODEL_1cc383629dac4ae99a1dec534c922b24",
            "value": " 232k/232k [00:00&lt;00:00, 1.71MB/s]"
          }
        },
        "55bb1f13e6774d52864b15ded2f82153": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b15c7c63774f45bdbbfe2a60a24a33c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7eb647d0ac494e568d27244abda8d574": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ccc3a4433c445d99af996eb4614a2c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5b74bde0f6045cb8935b18de2459e02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60d697c50e7546e3a054128d1c6ed158": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cc383629dac4ae99a1dec534c922b24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2104928226b640ae88b9611b3912c776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_409256a556f641cb9990640426c09c98",
              "IPY_MODEL_8c0b531402184c90be5e62ea8f8145a4",
              "IPY_MODEL_7f201c8750a0413aa6a179736394c3bc"
            ],
            "layout": "IPY_MODEL_06655be985174439a0886bd95ecd63eb"
          }
        },
        "409256a556f641cb9990640426c09c98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb648162ad5c4bfb98069125f02408ed",
            "placeholder": "​",
            "style": "IPY_MODEL_054a0ee86f5948ed8062862433ff4fdb",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "8c0b531402184c90be5e62ea8f8145a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f708e8844b445b9ab0b88d072c80b94",
            "max": 17756393,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ddd32bcea2f4fd2970c07878fa91a4c",
            "value": 17756393
          }
        },
        "7f201c8750a0413aa6a179736394c3bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bca374f044bd4d6d98e7a14d3e3b405f",
            "placeholder": "​",
            "style": "IPY_MODEL_243aeafb129245938f276995dcd1caf2",
            "value": " 17.8M/17.8M [00:00&lt;00:00, 31.7MB/s]"
          }
        },
        "06655be985174439a0886bd95ecd63eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb648162ad5c4bfb98069125f02408ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "054a0ee86f5948ed8062862433ff4fdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f708e8844b445b9ab0b88d072c80b94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ddd32bcea2f4fd2970c07878fa91a4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bca374f044bd4d6d98e7a14d3e3b405f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "243aeafb129245938f276995dcd1caf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}